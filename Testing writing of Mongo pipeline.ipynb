{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Writing of a Mongo Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First set of basic file functions\n",
    "\n",
    "Basic reads and writes, and something to fetch the ETL config file (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_etl_config(file_name):\n",
    "    return os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "\n",
    "def write_pipeline(vqb_pipeline, file_name):\n",
    "    etl_config_path = get_etl_config(file_name)\n",
    "    # This functionn either appends a MONGO_PIPELINE to an existing ETL_config file or it will\n",
    "    # create a new ETL_config file and put a MONGO_PIPELINE in it\n",
    "    with open(etl_config_path, 'a+') as f:\n",
    "        pipeline_to_write = f'MONGO_PIPELINE: {vqb_pipeline}'\n",
    "        f.write(pipeline_to_write)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def read_file():\n",
    "    with open(get_etl_config('etl_config.cson'), 'r') as f:\n",
    "        print('file contents ', f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that a simple build is added to ETL_config file\n",
    "\n",
    "This will make sure that we can write a pipeline not built yet by the server into the file\n",
    "* We first build a MONGO_PIPELINE with three stages (this is the same kind of example used in other parts of this notebook)\n",
    "* We then will feed this pipeline to the file to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'output_domain': 'purple',\n",
       "  'query': [{'$match': {'domain': 'test_data',\n",
       "     'color': 'purple',\n",
       "     'number': {'$lte': 50}}}]},\n",
       " {'output_domain': 'orange',\n",
       "  'query': [{'$match': {'domain': 'test_data',\n",
       "     'color': 'orange',\n",
       "     'number': {'$gt': 50}}}]},\n",
       " {'output_domain': 'result',\n",
       "  'query': [{'$match': {'domain': 'purple', 'color': 'purple'}},\n",
       "   {'$group': {'_id': None, '_vqbPipelineInline': {'$push': '$$ROOT'}}},\n",
       "   {'$lookup': {'from': 'orange',\n",
       "     'pipeline': [{'$match': {}}, {'$project': {'_id': 0}}],\n",
       "     'as': '_vqbPipelineToAppend_0'}},\n",
       "   {'$project': {'_vqbPipelinesUnion': {'$concatArrays': ['$_vqbPipelineInline',\n",
       "       '$_vqbPipelineToAppend_0']}}},\n",
       "   {'$unwind': '$_vqbPipelinesUnion'},\n",
       "   {'$replaceRoot': {'newRoot': '$_vqbPipelinesUnion'}}]}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_pipeline_step(output_col, mongo_query):\n",
    "    return {\n",
    "        'output_domain': output_col,\n",
    "        'query' : [mongo_query]\n",
    "    }\n",
    "\n",
    "def build_appendy_list(col):\n",
    "    return [\n",
    "    { '$match' : { 'domain' : 'purple', 'color' : 'purple' } },\n",
    "    *append_col_stages(col)\n",
    "]\n",
    "\n",
    "PURPLE_LIST = [{ '$match' : { 'domain' : 'test_data', 'color' : 'purple', 'number' : { '$lte' : 50 } } }]\n",
    "APPENDY_LIST = build_appendy_list('orange')\n",
    "\n",
    "def append_col_stages(col):\n",
    "    return [\n",
    "        {\n",
    "            \"$group\": {\n",
    "              \"_id\": None,\n",
    "              \"_vqbPipelineInline\": {\n",
    "                \"$push\": \"$$ROOT\"\n",
    "              }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$lookup\": {\n",
    "              \"from\": col,\n",
    "              \"pipeline\": [\n",
    "                {\n",
    "                  \"$match\": {}\n",
    "                },\n",
    "                {\n",
    "                  \"$project\": {\n",
    "                    \"_id\": 0\n",
    "                  }\n",
    "                }\n",
    "              ],\n",
    "              \"as\": \"_vqbPipelineToAppend_0\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "              \"_vqbPipelinesUnion\": {\n",
    "                \"$concatArrays\": [\n",
    "                  \"$_vqbPipelineInline\",\n",
    "                  \"$_vqbPipelineToAppend_0\"\n",
    "                ]\n",
    "              }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$unwind\": \"$_vqbPipelinesUnion\"\n",
    "        },\n",
    "        {\n",
    "            \"$replaceRoot\": {\n",
    "              \"newRoot\": \"$_vqbPipelinesUnion\"\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "TEST_VQB_PIPELINE = [\n",
    "    {\n",
    "        'output_domain' : 'purple',\n",
    "        'query' : PURPLE_LIST\n",
    "    },\n",
    "    {\n",
    "        'output_domain' : 'orange',\n",
    "        'query' : [\n",
    "            { '$match' : { 'domain' : 'test_data', 'color' : 'orange', 'number' : { '$gt' : 50 } } }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'output_domain' : 'result',\n",
    "        'query' : APPENDY_LIST\n",
    "    }\n",
    "]\n",
    "\n",
    "TEST_VQB_PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file contents  MONGO_PIPELINE: [{'output_domain': 'purple', 'query': [{'$match': {'domain': 'test_data', 'color': 'purple', 'number': {'$lte': 50}}}]}, {'output_domain': 'orange', 'query': [{'$match': {'domain': 'test_data', 'color': 'orange', 'number': {'$gt': 50}}}]}, {'output_domain': 'result', 'query': [{'$match': {'domain': 'purple', 'color': 'purple'}}, {'$group': {'_id': None, '_vqbPipelineInline': {'$push': '$$ROOT'}}}, {'$lookup': {'from': 'orange', 'pipeline': [{'$match': {}}, {'$project': {'_id': 0}}], 'as': '_vqbPipelineToAppend_0'}}, {'$project': {'_vqbPipelinesUnion': {'$concatArrays': ['$_vqbPipelineInline', '$_vqbPipelineToAppend_0']}}}, {'$unwind': '$_vqbPipelinesUnion'}, {'$replaceRoot': {'newRoot': '$_vqbPipelinesUnion'}}]}]\n"
     ]
    }
   ],
   "source": [
    "write_pipeline(TEST_VQB_PIPELINE, 'etl_config.cson')\n",
    "read_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens if a concepteur wants to update their ETL_config?\n",
    "\n",
    "We will emulate this by using a factory function to build the steps of a VQB pipeline and replace that pipeline in the ETL_config\n",
    "NOTE: it's more than likely that this following write function will be used instead of the simple one tested above since the file will most likely exist already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'output_domain': 'purple', 'query': [{'$match': {'domain': 'test_data', 'color': 'purple', 'number': {'$lte': 50}}}]}, {'output_domain': 'red', 'query': {'$match': {'domain': 'test_data', 'color': 'red', 'number': {'$gt': 50}}}}, {'output_domain': 'result', 'query': [{'$match': {'domain': 'purple', 'color': 'purple'}}, {'$group': {'_id': None, '_vqbPipelineInline': {'$push': '$$ROOT'}}}, {'$lookup': {'from': 'red', 'pipeline': [{'$match': {}}, {'$project': {'_id': 0}}], 'as': '_vqbPipelineToAppend_0'}}, {'$project': {'_vqbPipelinesUnion': {'$concatArrays': ['$_vqbPipelineInline', '$_vqbPipelineToAppend_0']}}}, {'$unwind': '$_vqbPipelinesUnion'}, {'$replaceRoot': {'newRoot': '$_vqbPipelinesUnion'}}]}]\n"
     ]
    }
   ],
   "source": [
    "def build_pipeline_step(domain_col, agg_array):\n",
    "    return {\n",
    "        'output_domain' : domain_col,\n",
    "        'query' : agg_array\n",
    "    }\n",
    "\n",
    "def build_pipeline(arr_of_outputs, arr_of_queries):\n",
    "    return [build_pipeline_step(arr_of_outputs[i], arr_of_queries[i]) for i in range(len(arr_of_outputs))]\n",
    "\n",
    "# NOTE: we're changing the old pipeline from looking for orange stuff to looking for red stuff\n",
    "arr_of_outputs = ['purple', 'red', 'result']\n",
    "arr_of_queries = [\n",
    "    PURPLE_LIST,\n",
    "    { '$match' : { 'domain' : 'test_data', 'color' : 'red', 'number' : { '$gt' : 50 } } },\n",
    "    build_appendy_list('red')\n",
    "]\n",
    "\n",
    "new_vqb_pipeline = build_pipeline(arr_of_outputs, arr_of_queries)\n",
    "print(new_vqb_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part : replacing the old Mongo pipeline with the new one\n",
    "The problem is that we will have to always have the MONGO_PIPELINE at the end of the file for this current thing to work\n",
    "\n",
    "We can't assume that the file already exists so there are three possibilities:\n",
    "* We have to create a new file and put a MONGO_PIPELINE in it\n",
    "* The file exists but there is no MONGO_PIPELINE in it\n",
    "* The file exists but there is already a MONGO_PIPELINE in it\n",
    "\n",
    "We want to replace any old MONGO_PIPELINE arrays with the new one, otherwise we just add the new MONGO_PIPELINE to the end of any existing contents inside the etl_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def update_pipeline_in_file(vqb_pipeline, file_name):\n",
    "    etl_config_path = get_etl_config(file_name)\n",
    "    try:\n",
    "        old_etl_config = open(etl_config_path, 'r')\n",
    "        replacement_string = f'MONGO_PIPELINE: {vqb_pipeline}'\n",
    "        contents = old_etl_config.read()\n",
    "        if 'MONGO_PIPELINE' in contents:\n",
    "            new_contents = re.sub(r'(MONGO_PIPELINE:)([\\W\\w]+)', replacement_string, contents, re.M)\n",
    "        else:\n",
    "            new_contents = f'{contents}{replacement_string}'\n",
    "        etl_config_to_update = open(etl_config_path, 'w+')\n",
    "        etl_config_to_update.write(new_contents)\n",
    "    except FileNotFoundError:\n",
    "        write_pipeline(vqb_pipeline, file_name)\n",
    "\n",
    "\n",
    "update_pipeline_in_file(new_vqb_pipeline, 'etl_config.cson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making sure that our update_pipeline_in_file function works for an etl_config with other contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_file_name = 'another_etl_config.cson'\n",
    "\n",
    "update_pipeline_in_file(new_vqb_pipeline, other_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
